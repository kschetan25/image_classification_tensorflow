{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model for prediction in future.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the x_train pickle data\n",
    "read_x_train = open(\"x_train.pickle\", \"rb\")\n",
    "x_train = pickle.load(read_x_train)\n",
    "\n",
    "# read the x_train pickle data\n",
    "read_y_train = open(\"y_train.pickle\", \"rb\")\n",
    "y_train = pickle.load(read_y_train)\n",
    "\n",
    "#Normalizing the data\n",
    "x_train = x_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_classification_grapg_1581471222\n",
      "Train on 26416 samples, validate on 11322 samples\n",
      "Epoch 1/10\n",
      "26416/26416 [==============================] - 162s 6ms/sample - loss: 0.6316 - acc: 0.6849 - val_loss: 0.5239 - val_acc: 0.7563\n",
      "Epoch 2/10\n",
      "26416/26416 [==============================] - 171s 6ms/sample - loss: 0.4464 - acc: 0.7936 - val_loss: 0.3960 - val_acc: 0.8227\n",
      "Epoch 3/10\n",
      "26416/26416 [==============================] - 158s 6ms/sample - loss: 0.3696 - acc: 0.8367 - val_loss: 0.3764 - val_acc: 0.8309\n",
      "Epoch 4/10\n",
      "26416/26416 [==============================] - 172s 7ms/sample - loss: 0.3184 - acc: 0.8596 - val_loss: 0.3455 - val_acc: 0.8484\n",
      "Epoch 5/10\n",
      "26416/26416 [==============================] - 152s 6ms/sample - loss: 0.2824 - acc: 0.8786 - val_loss: 0.3002 - val_acc: 0.8691\n",
      "Epoch 6/10\n",
      "26416/26416 [==============================] - 186s 7ms/sample - loss: 0.2557 - acc: 0.8926 - val_loss: 0.2927 - val_acc: 0.8775\n",
      "Epoch 7/10\n",
      "26416/26416 [==============================] - 160s 6ms/sample - loss: 0.2281 - acc: 0.9040 - val_loss: 0.3354 - val_acc: 0.8563\n",
      "Epoch 8/10\n",
      "26416/26416 [==============================] - 189s 7ms/sample - loss: 0.2062 - acc: 0.9157 - val_loss: 0.3015 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "26416/26416 [==============================] - 171s 6ms/sample - loss: 0.1842 - acc: 0.9234 - val_loss: 0.2939 - val_acc: 0.8809\n",
      "Epoch 10/10\n",
      "26416/26416 [==============================] - 164s 6ms/sample - loss: 0.1664 - acc: 0.9328 - val_loss: 0.3349 - val_acc: 0.8668\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN network to train the model\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "convolution_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for convolution_layer in convolution_layers:\n",
    "            graph_name = \"image_classification_grapg_{}\".format(int(time.time()))\n",
    "            print(graph_name)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=x_train.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for i in range(convolution_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for j in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(3))\n",
    "            model.add(Activation('softmax'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(graph_name))\n",
    "\n",
    "            model.compile(loss='sparse_categorical_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=32,                            #send 32 images in a batch\n",
    "                      epochs=10,                                #train the model for n epochs\n",
    "                      validation_split=0.3,                     #split train and test data\n",
    "                      callbacks=[tensorboard])\n",
    "\n",
    "            \n",
    "#Save the model\n",
    "model.save('image_classification_CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37738/37738 [==============================] - 48s 1ms/sample - loss: 0.2096 - acc: 0.9162\n",
      "0.20961590983497552 0.91623825\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy on validation data\n",
    "val_loss, val_acc = model.evaluate(x_train, y_train)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
